{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "INPUT_NODE = 784\n",
    "OUTPUT_NODE = 10\n",
    "\n",
    "LAYER1_NODE = 500\n",
    "\n",
    "LEARNING_RATE_BASE = 0.8\n",
    "LEARNING_RATE_DECAY = 0.99\n",
    "\n",
    "REGULARIZATION_RATE = 0.0001\n",
    "TRAING_STEP = 3000\n",
    "MOVING_AVERAGE_DECAY = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(input_tensor, avg_class, W1, b1, W2, b2):\n",
    "    if (avg_class == None):\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, W1) + b1)\n",
    "        return tf.matmul(layer1, W2) + b2\n",
    "    else:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, avg_class.average(W1)) + avg_class.average(b1))\n",
    "        return tf.matmul(layer1, avg_class.average(W2)) + avg_class.average(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mnist):\n",
    "    x = tf.placeholder(tf.float32, shape=[None, INPUT_NODE], name=\"X-input\")\n",
    "    y = tf.placeholder(tf.float32, shape=[None, OUTPUT_NODE], name=\"Y-input\")\n",
    "    \n",
    "    #第一層隱藏層\n",
    "    W1 = tf.Variable(tf.random_normal([INPUT_NODE, LAYER1_NODE], stddev=0.1))\n",
    "    b1 = tf.Variable(tf.zeros(shape=[LAYER1_NODE]))\n",
    "    #輸出層\n",
    "    W2 = tf.Variable(tf.random_normal([LAYER1_NODE, OUTPUT_NODE], stddev=0.1))\n",
    "    b2 =  tf.Variable(tf.zeros(shape=[OUTPUT_NODE]))\n",
    "    \n",
    "    y_ = inference(x, None, W1, b1, W2, b2)\n",
    "    \n",
    "    #定義存儲訓練輪數的變量\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    \n",
    "    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n",
    "    \n",
    "    variable_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "    \n",
    "    average_y = inference(x, variable_averages, W1, b1, W2, b2)\n",
    "    \n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_ , \n",
    "                                                                   labels=tf.argmax(y, 1))\n",
    "    #計算當前batch中所有cross_entropy平均值\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    regulatizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)\n",
    "    regularization = regulatizer(W1) + regulatizer(W2)\n",
    "    \n",
    "    loss = cross_entropy_mean + regularization\n",
    "    \n",
    "    learning_rate = tf.train.exponential_decay(LEARNING_RATE_BASE, \n",
    "                                               global_step, \n",
    "                                               mnist.train.num_examples / BATCH_SIZE, \n",
    "                                               LEARNING_RATE_DECAY)\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    #先不執行optimizer先執行variable_averages_op\n",
    "    with tf.control_dependencies([optimizer, variable_averages_op]):\n",
    "        optimizer = tf.no_op(name=\"train\")\n",
    "        \n",
    "    correct_prediction = tf.equal(tf.argmax(average_y, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        \n",
    "        #驗證集\n",
    "        validate_feed = {x: mnist.validation.images, y: mnist.validation.labels}\n",
    "        test_feed = {x: mnist.test.images, y: mnist.test.labels}\n",
    "        \n",
    "        for i in range(6000):\n",
    "            \n",
    "            if (i % 1000 == 0):\n",
    "                validate_acc = sess.run(accuracy, feed_dict=validate_feed)\n",
    "                print(\"After %d training step(s), validation accuracy using avarage model is %g\" % (i, validate_acc))\n",
    "                \n",
    "            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "            sess.run(optimizer, feed_dict={x :xs, y:ys})\n",
    "            \n",
    "        test_acc = sess.run(accuracy, feed_dict=test_feed)\n",
    "        print(\"After %d training step(s), test accuracy using avarage model is %g\" % (30000, test_acc))\n",
    "        \n",
    "def main(argv=None):\n",
    "#     mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "    train(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 training step(s), validation accuracy using avarage model is 0.1202\n",
      "After 1000 training step(s), validation accuracy using avarage model is 0.9766\n",
      "After 2000 training step(s), validation accuracy using avarage model is 0.9824\n",
      "After 3000 training step(s), validation accuracy using avarage model is 0.9834\n",
      "After 4000 training step(s), validation accuracy using avarage model is 0.9846\n",
      "After 5000 training step(s), validation accuracy using avarage model is 0.986\n",
      "After 30000 training step(s), test accuracy using avarage model is 0.9827\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Philip\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
