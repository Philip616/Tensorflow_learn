{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 30\n",
    "NUM_LAYERS = 2\n",
    "\n",
    "TIMESTEPS = 10\n",
    "TRAINING_STEPS = 3000\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "TRAINING_EXAMPLES = 10000\n",
    "TESTING_EXAMPLES = 1000\n",
    "SAMPLE_GAP = 0.01              #採樣間隔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(seq):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(len(seq) - TIMESTEPS):\n",
    "        #序列的第i項到 i+TIMESTEPS-1項作為輸入，第i+TIMESTEPS項為輸出，即用sin函數前面TIMESTEPS個訊息，預測第i+TIMESTEPS的函數值\n",
    "        X.append([seq[i: i + TIMESTEPS]])\n",
    "        y.append([seq[i + TIMESTEPS]])\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.float32)\n",
    "\n",
    "test_start = (TRAINING_EXAMPLES + TIMESTEPS) * SAMPLE_GAP\n",
    "test_end = test_start  + (TESTING_EXAMPLES + TIMESTEPS) * SAMPLE_GAP\n",
    "\n",
    "#np.linspace可以創建一個等差序列數組\n",
    "train_X, train_y = generate_data(np.sin(np.linspace(0, test_start, TRAINING_EXAMPLES + TIMESTEPS, dtype=np.float32)))\n",
    "test_X, test_y = generate_data(np.sin(np.linspace(test_start, test_end, TESTING_EXAMPLES + TIMESTEPS, dtype=np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(X, y, is_training):\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell([\n",
    "        tf.nn.rnn_cell.BasicLSTMCell(HIDDEN_SIZE) \n",
    "        for _ in range(NUM_LAYERS)]) \n",
    "    \n",
    "    output, _ = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "    #因只關注最後一個輸出結果\n",
    "    output = output[:, -1, :]\n",
    "    \n",
    "    predictions = tf.contrib.layers.fully_connected(output, 1, activation_fn=None)\n",
    "    \n",
    "    #測試時直接返回預測值\n",
    "    if not is_training:\n",
    "        return predictions, None, None\n",
    "    \n",
    "    loss = tf.losses.mean_squared_error(labels=y, predictions=predictions)\n",
    "    \n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "    loss, tf.train.get_global_step(),\n",
    "    optimizer='Adagrad', learning_rate = 0.1)\n",
    "    \n",
    "    return predictions, loss, train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval(sess, test_X, test_y):\n",
    "    # 将测试数据以数据集的方式提供给计算图。\n",
    "    ds = tf.data.Dataset.from_tensor_slices((test_X, test_y))\n",
    "    ds = ds.batch(1)\n",
    "    X, y = ds.make_one_shot_iterator().get_next()\n",
    "    \n",
    "    # 调用模型得到计算结果。这里不需要输入真实的y值。\n",
    "    with tf.variable_scope(\"model\", reuse=True):\n",
    "        prediction, _, _ = lstm_model(X, [0.0], False)\n",
    "    \n",
    "    # 将预测结果存入一个数组。\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for i in range(TESTING_EXAMPLES):\n",
    "        p, l = sess.run([prediction, y])\n",
    "        predictions.append(p)\n",
    "        labels.append(l)\n",
    "\n",
    "    # 计算rmse作为评价指标。\n",
    "    predictions = np.array(predictions).squeeze()\n",
    "    labels = np.array(labels).squeeze()\n",
    "    rmse = np.sqrt(((predictions - labels) ** 2).mean(axis=0))\n",
    "    print(\"Root Mean Square Error is: %f\" % rmse)\n",
    "    \n",
    "    #对预测的sin函数曲线进行绘图。\n",
    "    plt.figure()\n",
    "    plt.plot(predictions, label='predictions')\n",
    "    plt.plot(labels, label='real_sin')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate model before training.\n",
      "Root Mean Square Error is: 0.685448\n",
      "train step: 0, loss: 0.473202\n",
      "train step: 1000, loss: 0.00134407\n",
      "train step: 2000, loss: 0.000296844\n",
      "Evaluate model after training.\n",
      "Root Mean Square Error is: 0.008482\n"
     ]
    }
   ],
   "source": [
    "# 将训练数据以数据集的方式提供给计算图。\n",
    "ds = tf.data.Dataset.from_tensor_slices((train_X, train_y))\n",
    "ds = ds.repeat().shuffle(1000).batch(BATCH_SIZE)\n",
    "X, y = ds.make_one_shot_iterator().get_next()\n",
    "\n",
    "# 定义模型，得到预测结果、损失函数，和训练操作。\n",
    "with tf.variable_scope(\"model\"):\n",
    "    _, loss, train_op = lstm_model(X, y, True)\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # 测试在训练之前的模型效果。\n",
    "    print (\"Evaluate model before training.\")\n",
    "    run_eval(sess, test_X, test_y)\n",
    "    \n",
    "    # 训练模型。\n",
    "    for i in range(TRAINING_STEPS):\n",
    "        _, l = sess.run([train_op, loss])\n",
    "        if i % 1000 == 0:\n",
    "            print(\"train step: \" + str(i) + \", loss: \" + str(l))\n",
    "    \n",
    "    # 使用训练好的模型对测试数据进行预测。\n",
    "    print (\"Evaluate model after training.\")\n",
    "    run_eval(sess, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
